{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f\\anaconda3\\envs\\BigDataProject\\Lib\\site-packages\\pyspark\n"
     ]
    }
   ],
   "source": [
    "from pyspark.find_spark_home import _find_spark_home\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, StorageLevel\n",
    "from pyspark.sql.functions import col, count, when, lit\n",
    "import os\n",
    "\n",
    "print(_find_spark_home())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up PySpark configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('spark.app.name', 'CovidAgeComparison')\n",
      "('spark.pyspark.driver.python', 'C:\\\\Users\\x0c\\\\anaconda3\\\\envs\\\\BigDataProject\\\\python.exe')\n",
      "('spark.driver.port', '53688')\n",
      "('spark.driver.host', '192.168.0.14')\n",
      "('spark.app.id', 'local-1703092586496')\n",
      "('spark.executor.id', 'driver')\n",
      "('spark.executor.memory', '6g')\n",
      "('spark.driver.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false')\n",
      "('spark.app.submitTime', '1703092585366')\n",
      "('spark.rdd.compress', 'True')\n",
      "('spark-local-dir', 'C:\\\\spark-temp')\n",
      "('spark.driver.memory', '8g')\n",
      "('spark.serializer.objectStreamReset', '100')\n",
      "('spark.master', 'local[*]')\n",
      "('spark.submit.pyFiles', '')\n",
      "('spark.submit.deployMode', 'client')\n",
      "('spark.app.startTime', '1703092585507')\n",
      "('spark.pyspark.python', 'C:\\\\Users\\x0c\\\\anaconda3\\\\envs\\\\BigDataProject\\\\python.exe')\n",
      "('spark.ui.showConsoleProgress', 'true')\n",
      "('spark.driver.maxResultSize', '4g')\n",
      "('spark.executor.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false')\n"
     ]
    }
   ],
   "source": [
    "conf = (\n",
    "    SparkConf()\n",
    "    .setMaster(\"local[*]\")\n",
    "    .set(\"spark-local-dir\", \"C:\\\\spark-temp\")\n",
    "    .set(\"spark.driver.memory\", \"8g\")\n",
    "    .set(\"spark.executor.memory\", \"6g\")\n",
    "    .set(\"spark.driver.maxResultSize\", \"4g\")\n",
    "    .set(\n",
    "        \"spark.pyspark.python\",\n",
    "        \"C:\\\\Users\\f\\\\anaconda3\\\\envs\\\\BigDataProject\\python.exe\",\n",
    "    )\n",
    "    .set(\n",
    "        \"spark.pyspark.driver.python\",\n",
    "        \"C:\\\\Users\\f\\\\anaconda3\\\\envs\\\\BigDataProject\\python.exe\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CovidAgeComparison\").config(conf=conf).getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "for item in sc.getConf().getAll():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading CSV file from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to CSV file in HDFS\n",
    "csv_file_path = (\n",
    "    \"hdfs://localhost:9000/mydataset/COVID-19_Case_Surveillance_Public_Use_Data.csv\"\n",
    ")\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primary exploration of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------+-----------+----------+--------------------+------+-------------+-----------------------+-------+-------+--------+----------+\n",
      "|cdc_case_earliest_dt |cdc_report_dt|pos_spec_dt|  onset_dt|      current_status|   sex|    age_group|race_ethnicity_combined|hosp_yn| icu_yn|death_yn|medcond_yn|\n",
      "+---------------------+-------------+-----------+----------+--------------------+------+-------------+-----------------------+-------+-------+--------+----------+\n",
      "|           2022/11/10|   2022/11/11|       null|2022/11/10|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|     No|Missing|      No|   Missing|\n",
      "|           2022/09/01|   2022/09/01|       null|2022/09/01|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|     No|Missing|      No|   Missing|\n",
      "|           2020/12/28|   2021/01/07|       null|2020/12/28|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|     No|Missing|      No|   Missing|\n",
      "|           2021/12/18|   2021/12/28| 2021/12/24|2021/12/18|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|     No|Missing|      No|       Yes|\n",
      "|           2021/04/08|   2023/06/23|       null|      null|       Probable Case|Female|20 - 29 Years|    White, Non-Hispanic|     No|Missing|      No|   Missing|\n",
      "|           2022/06/21|   2022/06/23| 2022/06/21|      null|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Missing|Missing| Missing|   Missing|\n",
      "|           2021/11/27|   2022/02/21|       null|2021/11/27|       Probable Case|Female|20 - 29 Years|    White, Non-Hispanic|     No|     No|      No|   Missing|\n",
      "|           2021/09/15|   2021/09/16|       null|2021/09/15|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Missing|Missing| Missing|   Missing|\n",
      "|           2020/12/17|   2020/12/17|       null|      null|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Unknown|Missing|      No|   Missing|\n",
      "|           2022/11/02|   2023/04/22|       null|      null|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Missing|Missing|      No|   Missing|\n",
      "|           2021/11/05|   2021/11/08| 2021/11/07|2021/11/05|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Unknown|Missing| Unknown|        No|\n",
      "|           2020/11/30|   2022/05/04| 2020/11/30|      null|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Unknown|Unknown|      No|   Unknown|\n",
      "|           2022/01/20|   2022/01/23| 2022/01/22|2022/01/20|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Unknown|Missing| Unknown|        No|\n",
      "|           2020/06/27|   2020/07/04| 2020/06/27|2020/06/27|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|     No|     No|      No|        No|\n",
      "|           2021/08/19|   2021/08/19|       null|      null|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Unknown|Unknown| Unknown|        No|\n",
      "|           2022/09/16|   2022/09/18|       null|      null|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Missing|Missing|      No|   Missing|\n",
      "|           2021/04/12|   2023/06/23| 2021/04/12|      null|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Unknown|Unknown|      No|   Unknown|\n",
      "|           2021/07/22|   2021/07/23|       null|2021/07/22|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|     No|Missing|      No|   Missing|\n",
      "|           2021/02/26|   2021/03/08|       null|2021/02/26|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|     No|Missing|      No|   Missing|\n",
      "|           2020/11/27|   2020/11/28| 2020/11/27|2020/11/27|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|     No|Missing|      No|   Missing|\n",
      "+---------------------+-------------+-----------+----------+--------------------+------+-------------+-----------------------+-------+-------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101766479"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the amount of instances we have\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cdc_case_earliest_dt : string (nullable = true)\n",
      " |-- cdc_report_dt: string (nullable = true)\n",
      " |-- pos_spec_dt: string (nullable = true)\n",
      " |-- onset_dt: string (nullable = true)\n",
      " |-- current_status: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age_group: string (nullable = true)\n",
      " |-- race_ethnicity_combined: string (nullable = true)\n",
      " |-- hosp_yn: string (nullable = true)\n",
      " |-- icu_yn: string (nullable = true)\n",
      " |-- death_yn: string (nullable = true)\n",
      " |-- medcond_yn: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring the types of columns we have in the dataset\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|      current_status|   count|\n",
      "+--------------------+--------+\n",
      "|       Probable Case|17862700|\n",
      "|Laboratory-confir...|83903779|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring current_status column\n",
    "df.groupBy(col(\"current_status\")).agg(count(\"current_status\").alias(\"count\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigDataProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
