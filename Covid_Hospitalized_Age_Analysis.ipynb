{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f\\anaconda3\\envs\\BigDataProject\\Lib\\site-packages\\pyspark\n"
     ]
    }
   ],
   "source": [
    "from pyspark.find_spark_home import _find_spark_home\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, StorageLevel\n",
    "from pyspark.sql.functions import col, count, when, lit\n",
    "import os\n",
    "\n",
    "print(_find_spark_home())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up PySpark configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('spark.app.name', 'CovidAgeComparison')\n",
      "('spark.pyspark.driver.python', 'C:\\\\Users\\x0c\\\\anaconda3\\\\envs\\\\BigDataProject\\\\python.exe')\n",
      "('spark.driver.port', '53688')\n",
      "('spark.driver.host', '192.168.0.14')\n",
      "('spark.app.id', 'local-1703092586496')\n",
      "('spark.executor.id', 'driver')\n",
      "('spark.executor.memory', '6g')\n",
      "('spark.driver.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false')\n",
      "('spark.app.submitTime', '1703092585366')\n",
      "('spark.rdd.compress', 'True')\n",
      "('spark-local-dir', 'C:\\\\spark-temp')\n",
      "('spark.driver.memory', '8g')\n",
      "('spark.serializer.objectStreamReset', '100')\n",
      "('spark.master', 'local[*]')\n",
      "('spark.submit.pyFiles', '')\n",
      "('spark.submit.deployMode', 'client')\n",
      "('spark.app.startTime', '1703092585507')\n",
      "('spark.pyspark.python', 'C:\\\\Users\\x0c\\\\anaconda3\\\\envs\\\\BigDataProject\\\\python.exe')\n",
      "('spark.ui.showConsoleProgress', 'true')\n",
      "('spark.driver.maxResultSize', '4g')\n",
      "('spark.executor.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false')\n"
     ]
    }
   ],
   "source": [
    "conf = (\n",
    "    SparkConf()\n",
    "    .setMaster(\"local[*]\")\n",
    "    .set(\"spark-local-dir\", \"C:\\\\spark-temp\")\n",
    "    .set(\"spark.driver.memory\", \"8g\")\n",
    "    .set(\"spark.executor.memory\", \"6g\")\n",
    "    .set(\"spark.driver.maxResultSize\", \"4g\")\n",
    "    .set(\n",
    "        \"spark.pyspark.python\",\n",
    "        \"C:\\\\Users\\f\\\\anaconda3\\\\envs\\\\BigDataProject\\python.exe\",\n",
    "    )\n",
    "    .set(\n",
    "        \"spark.pyspark.driver.python\",\n",
    "        \"C:\\\\Users\\f\\\\anaconda3\\\\envs\\\\BigDataProject\\python.exe\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CovidAgeComparison\").config(conf=conf).getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "for item in sc.getConf().getAll():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading CSV file from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to CSV file in HDFS\n",
    "csv_file_path = (\n",
    "    \"hdfs://localhost:9000/mydataset/COVID-19_Case_Surveillance_Public_Use_Data.csv\"\n",
    ")\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primary exploration of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------+-----------+----------+--------------------+------+-------------+-----------------------+-------+-------+--------+----------+\n",
      "|cdc_case_earliest_dt |cdc_report_dt|pos_spec_dt|  onset_dt|      current_status|   sex|    age_group|race_ethnicity_combined|hosp_yn| icu_yn|death_yn|medcond_yn|\n",
      "+---------------------+-------------+-----------+----------+--------------------+------+-------------+-----------------------+-------+-------+--------+----------+\n",
      "|           2022/11/10|   2022/11/11|       null|2022/11/10|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|     No|Missing|      No|   Missing|\n",
      "|           2022/09/01|   2022/09/01|       null|2022/09/01|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|     No|Missing|      No|   Missing|\n",
      "|           2020/12/28|   2021/01/07|       null|2020/12/28|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|     No|Missing|      No|   Missing|\n",
      "|           2021/12/18|   2021/12/28| 2021/12/24|2021/12/18|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|     No|Missing|      No|       Yes|\n",
      "|           2021/04/08|   2023/06/23|       null|      null|       Probable Case|Female|20 - 29 Years|    White, Non-Hispanic|     No|Missing|      No|   Missing|\n",
      "|           2022/06/21|   2022/06/23| 2022/06/21|      null|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Missing|Missing| Missing|   Missing|\n",
      "|           2021/11/27|   2022/02/21|       null|2021/11/27|       Probable Case|Female|20 - 29 Years|    White, Non-Hispanic|     No|     No|      No|   Missing|\n",
      "|           2021/09/15|   2021/09/16|       null|2021/09/15|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Missing|Missing| Missing|   Missing|\n",
      "|           2020/12/17|   2020/12/17|       null|      null|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Unknown|Missing|      No|   Missing|\n",
      "|           2022/11/02|   2023/04/22|       null|      null|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Missing|Missing|      No|   Missing|\n",
      "|           2021/11/05|   2021/11/08| 2021/11/07|2021/11/05|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Unknown|Missing| Unknown|        No|\n",
      "|           2020/11/30|   2022/05/04| 2020/11/30|      null|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Unknown|Unknown|      No|   Unknown|\n",
      "|           2022/01/20|   2022/01/23| 2022/01/22|2022/01/20|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Unknown|Missing| Unknown|        No|\n",
      "|           2020/06/27|   2020/07/04| 2020/06/27|2020/06/27|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|     No|     No|      No|        No|\n",
      "|           2021/08/19|   2021/08/19|       null|      null|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Unknown|Unknown| Unknown|        No|\n",
      "|           2022/09/16|   2022/09/18|       null|      null|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Missing|Missing|      No|   Missing|\n",
      "|           2021/04/12|   2023/06/23| 2021/04/12|      null|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|Unknown|Unknown|      No|   Unknown|\n",
      "|           2021/07/22|   2021/07/23|       null|2021/07/22|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|     No|Missing|      No|   Missing|\n",
      "|           2021/02/26|   2021/03/08|       null|2021/02/26|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|     No|Missing|      No|   Missing|\n",
      "|           2020/11/27|   2020/11/28| 2020/11/27|2020/11/27|Laboratory-confir...|Female|20 - 29 Years|    White, Non-Hispanic|     No|Missing|      No|   Missing|\n",
      "+---------------------+-------------+-----------+----------+--------------------+------+-------------+-----------------------+-------+-------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101766479"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the amount of instances we have\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cdc_case_earliest_dt : string (nullable = true)\n",
      " |-- cdc_report_dt: string (nullable = true)\n",
      " |-- pos_spec_dt: string (nullable = true)\n",
      " |-- onset_dt: string (nullable = true)\n",
      " |-- current_status: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age_group: string (nullable = true)\n",
      " |-- race_ethnicity_combined: string (nullable = true)\n",
      " |-- hosp_yn: string (nullable = true)\n",
      " |-- icu_yn: string (nullable = true)\n",
      " |-- death_yn: string (nullable = true)\n",
      " |-- medcond_yn: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring the types of columns we have in the dataset\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|      current_status|   count|\n",
      "+--------------------+--------+\n",
      "|       Probable Case|17862700|\n",
      "|Laboratory-confir...|83903779|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring current_status column\n",
    "df.groupBy(col(\"current_status\")).agg(count(\"current_status\").alias(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|      current_status|  count|\n",
      "+--------------------+-------+\n",
      "|Laboratory-confir...|4623658|\n",
      "+--------------------+-------+\n",
      "\n",
      "+----------+-------+\n",
      "|medcond_yn|  count|\n",
      "+----------+-------+\n",
      "|        No|4623658|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtering the instances that are confirmed and without a previous health condition\n",
    "df_filtered = df.filter(col(\"current_status\") != \"Probable Case\")\n",
    "df_filtered = df_filtered.filter(col(\"medcond_yn\") == \"No\")\n",
    "df_filtered.groupBy(col(\"current_status\")).agg(\n",
    "    count(\"current_status\").alias(\"count\")\n",
    ").show()\n",
    "df_filtered.groupBy(col(\"medcond_yn\")).agg(count(\"medcond_yn\").alias(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered dataset\n",
    "df_filtered.write.format(\"csv\").mode(\"overwrite\").save(\"hdfs://localhost:9000/mydataset/filtered/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4623658"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The new count after filtering\n",
    "df_filtered.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unwanted columns\n",
    "reduced_df = df_filtered.drop(\n",
    "    \"cdc_case_earliest_dt \",\n",
    "    \"cdc_report_dt\",\n",
    "    \"pos_spec_dt\",\n",
    "    \"onset_dt\",\n",
    "    \"current_status\",\n",
    "    \"sex\",\n",
    "    \"race_ethnicity_combined\",\n",
    "    \"icu_yn\",\n",
    "    \"death_yn\",\n",
    "    \"medcond_yn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|    age_group|hosp_yn|\n",
      "+-------------+-------+\n",
      "|20 - 29 Years|Unknown|\n",
      "|20 - 29 Years|Unknown|\n",
      "|20 - 29 Years|     No|\n",
      "|20 - 29 Years|Unknown|\n",
      "|20 - 29 Years|     No|\n",
      "|20 - 29 Years|Unknown|\n",
      "|20 - 29 Years|Unknown|\n",
      "|20 - 29 Years|     No|\n",
      "|20 - 29 Years|     No|\n",
      "|20 - 29 Years|     No|\n",
      "|20 - 29 Years|Unknown|\n",
      "|20 - 29 Years|     No|\n",
      "|20 - 29 Years|     No|\n",
      "|20 - 29 Years|Unknown|\n",
      "|20 - 29 Years|     No|\n",
      "|20 - 29 Years|     No|\n",
      "|20 - 29 Years|Unknown|\n",
      "|20 - 29 Years|Unknown|\n",
      "|20 - 29 Years|     No|\n",
      "|20 - 29 Years|     No|\n",
      "+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reduced_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values and counts in column: age_group\n",
      "+-------------+------+\n",
      "|    age_group| count|\n",
      "+-------------+------+\n",
      "|20 - 29 Years|885723|\n",
      "|40 - 49 Years|622224|\n",
      "|50 - 59 Years|512153|\n",
      "|70 - 79 Years|193675|\n",
      "|  0 - 9 Years|479513|\n",
      "|30 - 39 Years|777522|\n",
      "|      Missing|   956|\n",
      "|10 - 19 Years|695394|\n",
      "|    80+ Years| 96854|\n",
      "|60 - 69 Years|359635|\n",
      "|           NA|     9|\n",
      "+-------------+------+\n",
      "\n",
      "Unique values and counts in column: hosp_yn\n",
      "+-------+-------+\n",
      "|hosp_yn|  count|\n",
      "+-------+-------+\n",
      "|Unknown|1853625|\n",
      "|     No|2270117|\n",
      "|    Yes| 114809|\n",
      "|Missing| 385107|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking what classes does the age_group and the hosp_yn columns has\n",
    "for col_name in reduced_df.columns:\n",
    "    print(f\"Unique values and counts in column: {col_name}\")\n",
    "    reduced_df.groupBy(col(col_name)).agg(count(col_name).alias(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning missing and not available data instances\n",
    "df_filtered2 = reduced_df.dropna()\n",
    "df_filtered2 = df_filtered2.filter(col(\"age_group\") != \"Missing\")\n",
    "df_filtered2 = df_filtered2.filter(col(\"age_group\") != \"NA\")\n",
    "df_filtered2 = df_filtered2.filter(col(\"hosp_yn\") != \"Missing\")\n",
    "df_filtered2 = df_filtered2.filter(col(\"hosp_yn\") != \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values and counts in column: age_group\n",
      "+-------------+------+\n",
      "|    age_group| count|\n",
      "+-------------+------+\n",
      "|20 - 29 Years|477964|\n",
      "|40 - 49 Years|316328|\n",
      "|50 - 59 Years|252701|\n",
      "|70 - 79 Years| 84511|\n",
      "|  0 - 9 Years|254104|\n",
      "|30 - 39 Years|400488|\n",
      "|10 - 19 Years|389182|\n",
      "|    80+ Years| 40645|\n",
      "|60 - 69 Years|168765|\n",
      "+-------------+------+\n",
      "\n",
      "Unique values and counts in column: hosp_yn\n",
      "+-------+-------+\n",
      "|hosp_yn|  count|\n",
      "+-------+-------+\n",
      "|     No|2269888|\n",
      "|    Yes| 114800|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking out what the columns look like after cleaning\n",
    "for col_name in df_filtered2.columns:\n",
    "    print(f\"Unique values and counts in column: {col_name}\")\n",
    "    df_filtered2.groupBy(col(col_name)).agg(count(col_name).alias(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing instances based on age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values and counts in column: hosp_yn\n",
      "+-------+-------+\n",
      "|hosp_yn|  count|\n",
      "+-------+-------+\n",
      "|     No|2269888|\n",
      "|    Yes| 114800|\n",
      "+-------+-------+\n",
      "\n",
      "Unique values and counts in column: age_category\n",
      "+------------+-------+\n",
      "|age_category|  count|\n",
      "+------------+-------+\n",
      "|    under 40|1521738|\n",
      "|    above 40| 862950|\n",
      "+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Devding age instances into two distinct categories above and under 40\n",
    "categorized_df = df_filtered2.withColumn(\n",
    "    \"age_category\",\n",
    "    when(\n",
    "        col(\"age_group\").isin(\n",
    "            \"0 - 9 Years\", \"10 - 19 Years\", \"20 - 29 Years\", \"30 - 39 Years\"\n",
    "        ),\n",
    "        \"under 40\",\n",
    "    ).otherwise(\"above 40\"),\n",
    ")\n",
    "\n",
    "# Dropping the old age column\n",
    "final_df = categorized_df.drop(\"age_group\")\n",
    "\n",
    "# Showing the results after the division\n",
    "for col_name in final_df.columns:\n",
    "    print(f\"Unique values and counts in column: {col_name}\")\n",
    "    final_df.groupBy(col(col_name)).agg(count(col_name).alias(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.write.format(\"csv\").mode(\"overwrite\").save(\"hdfs://localhost:9000/mydataset/finalDataset/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigDataProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
